{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Part 2\n",
    "> \"Python Data Science Handbook\" - *Jake Vanderplas (2016)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Datasets: Concat\n",
    "\n",
    "Some of the most interesting studies of data come from combining different data\n",
    "sources. These operations can involve anything from very straightforward concatena‐\n",
    "tion of two different datasets, to more complicated database-style joins and merges\n",
    "that correctly handle any overlaps between the datasets. Series and DataFrames are\n",
    "built with this type of operation in mind, and Pandas includes functions and methods\n",
    "that make this sort of data wrangling fast and straightforward.\n",
    "\n",
    "Here we’ll take a look at simple concatenation of Series and DataFrames with the\n",
    "pd.concat function; later we’ll dive into more sophisticated in-memory merges and\n",
    "joins implemented in Pandas.\n",
    "\n",
    "We begin with the standard imports:\n",
    "\n",
    "```python\n",
    "In[1]: import pandas as pd\n",
    " import numpy as np\n",
    "```\n",
    "\n",
    "For convenience, we’ll define this function, which creates a DataFrame of a particular\n",
    "form that will be useful below:\n",
    "```python\n",
    "In[2]:  def make_df(cols, ind):\n",
    "                \"\"\"Quickly make a DataFrame\"\"\"\n",
    "                data = {c: [str(c) + str(i) for i in ind] for c in cols}\n",
    "                return pd.DataFrame(data, ind)\n",
    "        # example DataFrame\n",
    "         make_df('ABC', range(3))\n",
    "\n",
    "Out[2]:   A  B  C\n",
    "        0 A0 B0 C0\n",
    "        1 A1 B1 C1\n",
    "        2 A2 B2 C2\n",
    "  ```\n",
    "## Simple Concatenation with pd.concat\n",
    "Pandas has a function, pd.concat(), which has a similar syntax to np.concatenate\n",
    "but contains a number of options that we’ll discuss momentarily:\n",
    "```python\n",
    "# Signature in Pandas v0.18\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,\n",
    " keys=None, levels=None, names=None, verify_integrity=False,\n",
    " copy=True)\n",
    " ```\n",
    "\n",
    "`pd.concat()` can be used for a simple concatenation of Series or DataFrame objects,\n",
    "just as `np.concatenate()` can be used for simple concatenations of arrays:\n",
    "```python\n",
    "In[6]:  ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3])\n",
    "        ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6])\n",
    "        pd.concat([ser1, ser2])\n",
    "Out[6]: 1 A\n",
    "        2 B\n",
    "        3 C\n",
    "        4 D\n",
    "        5 E\n",
    "        6 F\n",
    "        dtype: object\n",
    "```\n",
    "It also works to concatenate higher-dimensional objects, such as DataFrames:\n",
    "```python\n",
    "In[7]:  df1 = make_df('AB', [1, 2])\n",
    "        df2 = make_df('AB', [3, 4])\n",
    "        print(df1); print(df2); print(pd.concat([df1, df2]))\n",
    "        \n",
    "  df1           df2             pd.concat([df1, df2])\n",
    "   A  B            A  B           A B\n",
    " 1 A1 B1         3 A3 B3        1 A1 B1\n",
    " 2 A2 B2         4 A4 B4        2 A2 B2\n",
    " 3 A3 B3        \n",
    " 4 A4 B4        \n",
    "```\n",
    "By default, the concatenation takes place row-wise within the DataFrame (i.e.,\n",
    "axis=0). Like np.concatenate, pd.concat allows specification of an axis along which\n",
    "concatenation will take place. Consider the following example:\n",
    "```python\n",
    "In[8]:  df3 = make_df('AB', [0, 1])\n",
    "        df4 = make_df('CD', [0, 1])\n",
    "        print(df3); print(df4); print(pd.concat([df3, df4], axis='col'))\n",
    "        \n",
    "   df3            df4             pd.concat([df3, df4], axis='col')\n",
    "   A  B            C  D            A  B  C  D\n",
    " 0 A0 B0         0 C0 D0         0 A0 B0 C0 D0\n",
    " 1 A1 B1         1 C1 D1         1 A1 B1 C1 D1\n",
    "```\n",
    "We could have equivalently specified axis=1; here we’ve used the more intuitive\n",
    "`axis='col'`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try it yourself: Create a CSV file using excel with the ff conditions:\n",
    "1. Create 2 csv files with the same indices but different columns and merge using `concat` at `axis='col'`\n",
    "2. Create 2 csv files with the different indices but same columns and merge using `concat` at `axis='row'`\n",
    "\n",
    "Hint: When using colab, upload the files first to your colab environment. Copy the path and read using `pd.read_csv(<path>, index_col=0)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Datasets: Merge and Join\n",
    "\n",
    "## Categories of Joins\n",
    "The `pd.merge()` function implements a number of types of joins: the *one-to-one*,\n",
    "*many-to-one*, and *many-to-many joins*. All three types of joins are accessed via an\n",
    "identical call to the `pd.merge()` interface; the type of join performed depends on the\n",
    "form of the input data. Here we will show simple examples of the three types of\n",
    "merges, and discuss detailed options further below\n",
    "\n",
    "### One-to-one joins\n",
    "\n",
    "Perhaps the simplest type of merge expression is the one-to-one join, which is in\n",
    "many ways very similar to the column-wise concatenation seen in “Combining Data‐\n",
    "sets: Concat and Append” on page 141. As a concrete example, consider the following\n",
    "two DataFrames, which contain information on several employees in a company:\n",
    "```python\n",
    "In[2]:\n",
    "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
    "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
    "                    'hire_date': [2004, 2008, 2012, 2014]})\n",
    "print(df1); print(df2)\n",
    "df1                     df2\n",
    " employee group         employee  hire_date\n",
    "0 Bob   Accounting      0 Lisa  2004\n",
    "1 Jake  Engineering     1 Bob   2008\n",
    "2 Lisa  Engineering     2 Jake  2012\n",
    "3 Sue   HR              3 Sue   2014\n",
    "```\n",
    "To combine this information into a single DataFrame, we can use the pd.merge()\n",
    "function:\n",
    "\n",
    "```python\n",
    "In[3]: df3 = pd.merge(df1, df2)\n",
    " df3\n",
    "\n",
    "Out[3]: employee   group       hire_date\n",
    "        0 Bob      Accounting  2008\n",
    "        1 Jake     Engineering 2012\n",
    "        2 Lisa     Engineering 2004\n",
    "        3 Sue      HR          2014\n",
    "```\n",
    "\n",
    "The `pd.merge()` function recognizes that each DataFrame has an **“employee”** column,\n",
    "and automatically joins using this column as a key. The result of the merge is a new\n",
    "DataFrame that combines the information from the two inputs. Notice that the order\n",
    "of entries in each column is not necessarily maintained: in this case, the order of the\n",
    "**“employee”** column differs between df1 and df2, and the `pd.merge()` function cor‐\n",
    "rectly accounts for this.\n",
    "\n",
    "### Many-to-one joins\n",
    "Many-to-one joins are joins in which one of the two key columns contains duplicate\n",
    "entries. For the many-to-one case, the resulting DataFrame will preserve those dupli‐\n",
    "cate entries as appropriate. Consider the following example of a many-to-one join:\n",
    "```python\n",
    "In[4]:  df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
    "                           'supervisor': ['Carly', 'Guido', 'Steve']})\n",
    "        print(df3); print(df4); print(pd.merge(df3, df4))\n",
    "\n",
    "df3                                  df4\n",
    "  employee group      hire_date         group         supervisor\n",
    "0 Bob   Accounting   2008            0 Accounting    Carly\n",
    "1 Jake  Engineering  2012            1 Engineering   Guido\n",
    "2 Lisa  Engineering  2004            2 HR            Steve\n",
    "3 Sue   HR           2014\n",
    "\n",
    "pd.merge(df3, df4)\n",
    " employee group         hire_date supervisor\n",
    "0 Bob   Accounting      2008    Carly\n",
    "1 Jake  Engineering     2012    Guido\n",
    "2 Lisa  Engineering     2004    Guido\n",
    "3 Sue   HR              2014    Steve\n",
    "```\n",
    "The resulting DataFrame has an additional column with the `“supervisor”` information,\n",
    "where the information is repeated in one or more locations as required by the inputs.\n",
    "\n",
    "### Many-to-many joins\n",
    "Many-to-many joins are a bit confusing conceptually, but are nevertheless well\n",
    "defined. If the key column in both the left and right array contains duplicates, then\n",
    "the result is a many-to-many merge. This will be perhaps most clear with a concrete\n",
    "example. Consider the following, where we have a DataFrame showing one or more\n",
    "skills associated with a particular group.\n",
    "By performing a many-to-many join, we can recover the skills associated with any\n",
    "individual person:\n",
    "```python\n",
    "In[5]: df5 = pd.DataFrame({'group': ['Accounting', 'Accounting',\n",
    "                                        'Engineering', 'Engineering', 'HR', 'HR'],\n",
    "                           'skills': ['math', 'spreadsheets', 'coding', 'linux',\n",
    "                                        'spreadsheets', 'organization']})\n",
    "print(df1); print(df5); print(pd.merge(df1, df5))\n",
    "  df1                      df5\n",
    "  employee group           group         skills\n",
    "0 Bob   Accounting       0 Accounting    math\n",
    "1 Jake  Engineering      1 Accounting    spreadsheets\n",
    "2 Lisa  Engineering      2 Engineering   coding\n",
    "3 Sue   HR               3 Engineering   linux\n",
    "                         4 HR            spreadsheets\n",
    "                         5 HR            organization\n",
    "\n",
    "pd.merge(df1, df5)\n",
    "  employee group         skills\n",
    "0 Bob   Accounting      math\n",
    "1 Bob   Accounting      spreadsheets\n",
    "2 Jake  Engineering     coding\n",
    "3 Jake  Engineering     linux\n",
    "4 Lisa  Engineering     coding\n",
    "5 Lisa  Engineering     linux\n",
    "6 Sue   HR              spreadsheets\n",
    "7 Sue   HR              organization\n",
    "```\n",
    "\n",
    "\n",
    "These three types of joins can be used with other Pandas tools to implement a wide\n",
    "array of functionality. But in practice, datasets are rarely as clean as the one we’re\n",
    "working with here. In the following section, we’ll consider some of the options pro‐\n",
    "vided by pd.merge() that enable you to tune how the join operations work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of the Merge Key\n",
    "We’ve already seen the default behavior of pd.merge(): it looks for one or more\n",
    "matching column names between the two inputs, and uses this as the key. However,\n",
    "often the column names will not match so nicely, and pd.merge() provides a variety\n",
    "of options for handling this.\n",
    "\n",
    "### The `on` keyword\n",
    "Most simply, you can explicitly specify the name of the key column using the on key‐\n",
    "word, which takes a column name or a list of column names:\n",
    "```python\n",
    "In[6]: print(df1); print(df2); print(pd.merge(df1, df2, on='employee'))\n",
    "df1                        df2\n",
    "  employee group           employee hire_date\n",
    "0 Bob   Accounting       0 Lisa 2004\n",
    "1 Jake  Engineering      1 Bob 2008\n",
    "2 Lisa  Engineering      2 Jake 2012\n",
    "3 Sue   HR               3 Sue 2014\n",
    "\n",
    "pd.merge(df1, df2, on='employee')\n",
    " employee group         hire_date\n",
    "0 Bob   Accounting      2008\n",
    "1 Jake  Engineering     2012\n",
    "2 Lisa  Engineering     2004\n",
    "3 Sue   HR              2014\n",
    "```\n",
    "This option works only if both the left and right DataFrames have the specified col‐\n",
    "umn name.\n",
    "\n",
    "\n",
    "### The `left_on` and `right_on` keywords\n",
    "At times you may wish to merge two datasets with different column names; for exam‐\n",
    "ple, we may have a dataset in which the employee name is labeled as “name” rather\n",
    "than “employee”. In this case, we can use the left_on and right_on keywords to\n",
    "specify the two column names:\n",
    "```python\n",
    "In[7]:\n",
    "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
    "                    'salary': [70000, 80000, 120000, 90000]})\n",
    "print(df1), print(df3)\n",
    "print(pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\"))\n",
    "  df1                                  df3\n",
    "  employee group                       name  salary\n",
    "0 Bob    Accounting                  0 Bob   70000\n",
    "1 Jake   Engineering                 1 Jake  80000\n",
    "2 Lisa   Engineering                 2 Lisa  120000\n",
    "3 Sue    HR                          3 Sue   90000\n",
    "\n",
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\")\n",
    "  employee group       name    salary\n",
    "0 Bob   Accounting     Bob      70000\n",
    "1 Jake  Engineering    Jake     80000\n",
    "2 Lisa  Engineering    Lisa     120000\n",
    "3 Sue   HR             Sue      90000\n",
    "```\n",
    "The result has a redundant column that we can drop if desired—for example, by\n",
    "using the `drop()` method of DataFrames:\n",
    "```python\n",
    "In[8]:\n",
    "pd.merge(df1, df3, left_on=\"employee\", right_on=\"name\").drop('name', axis=1)\n",
    "Out[8]: employee group         salary\n",
    "        0 Bob   Accounting     70000\n",
    "        1 Jake  Engineering    80000\n",
    "        2 Lisa  Engineering    120000\n",
    "        3 Sue   HR             90000\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregation and Grouping\n",
    "An essential piece of analysis of large data is efficient summarization: computing\n",
    "aggregations like sum(), mean(), median(), min(), and max(), in which a single num‐\n",
    "ber gives insight into the nature of a potentially large dataset. In this section, we’llexplore aggregations in Pandas, from simple operations akin to what we’ve seen on\n",
    "NumPy arrays, to more sophisticated operations based on the concept of a groupby.\n",
    "## Planets Data\n",
    "Here we will use the Planets dataset, available via the Seaborn package. It gives information on planets that astronomers\n",
    "have discovered around other stars (known as extrasolar planets or exoplanets for\n",
    "short). It can be downloaded with a simple Seaborn command:\n",
    "```python\n",
    "In[2]:  import seaborn as sns\n",
    "        planets = sns.load_dataset('planets')\n",
    "        planets.shape\n",
    "Out[2]: (1035, 6)\n",
    "In[3]:  planets.head()\n",
    "Out[3]:   method          number    orbital_period  mass    distance year\n",
    "        0 Radial Velocity 1         269.300         7.10    77.40   2006\n",
    "        1 Radial Velocity 1         874.774         2.21    56.95   2008\n",
    "        2 Radial Velocity 1         763.000         2.60    19.84   2011\n",
    "        3 Radial Velocity 1         326.030         19.40   110.62  2007\n",
    "        4 Radial Velocity 1         516.220         10.50   119.47  2009\n",
    "```\n",
    "This has some details on the 1,000+ exoplanets discovered up to 2014.\n",
    "\n",
    "## GroupBy: Split, Apply, Combine\n",
    "Simple aggregations can give you a flavor of your dataset, but often we would prefer\n",
    "to aggregate conditionally on some label or index: this is implemented in the so￾called groupby operation. The name “group by” comes from a command in the SQL\n",
    "database language, but it is perhaps more illuminative to think of it in the terms first\n",
    "coined by Hadley Wickham of Rstats fame: split, apply, combine.\n",
    "### Split, apply, combine\n",
    "A canonical example of this split-apply-combine operation, where the “apply” is a\n",
    "summation aggregation, is illustrated in Figure 3-1.\n",
    "Figure 3-1 makes clear what the GroupBy accomplishes:\n",
    "* The split step involves breaking up and grouping a DataFrame depending on the\n",
    "value of the specified key.\n",
    "* The apply step involves computing some function, usually an aggregate, transfor‐\n",
    "mation, or filtering, within the individual groups.\n",
    "* The combine step merges the results of these operations into an output array.\n",
    "\n",
    "While we could certainly do this manually using some combination of the masking,\n",
    "aggregation, and merging commands covered earlier, it’s important to realize that the\n",
    "intermediate splits do not need to be explicitly instantiated. Rather, the GroupBy can\n",
    "(often) do this in a single pass over the data, updating the sum, mean, count, min, or\n",
    "other aggregate for each group along the way. The power of the GroupBy is that it\n",
    "abstracts away these steps: the user need not think about how the computation is\n",
    "done under the hood, but rather thinks about the operation as a whole.\n",
    "\n",
    "As a concrete example, we’ll start by creating the input DataFrame:\n",
    "```python\n",
    "In[11]: df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
    "                           'data': range(6)}, columns=['key', 'data'])\n",
    "        df\n",
    "Out[11]:         key data\n",
    "                0 A 0\n",
    "                1 B 1\n",
    "                2 C 2\n",
    "                3 A 3\n",
    "                4 B 4\n",
    "                5 C 5\n",
    "```\n",
    "We can compute the most basic split-apply-combine operation with the groupby()\n",
    "method of DataFrames, passing the name of the desired key column:\n",
    "\n",
    "```python\n",
    "In[12]: df.groupby('key')\n",
    "Out[12]: <pandas.core.groupby.DataFrameGroupBy object at 0x117272160>\n",
    "```\n",
    "\n",
    "Notice that what is returned is not a set of DataFrames, but a DataFrameGroupBy\n",
    "object. This object is where the magic is: you can think of it as a special view of the\n",
    "DataFrame, which is poised to dig into the groups but does no actual computation\n",
    "until the aggregation is applied. This “lazy evaluation” approach means that common\n",
    "aggregates can be implemented very efficiently in a way that is almost transparent to\n",
    "the user.\n",
    "\n",
    "To produce a result, we can apply an aggregate to this DataFrameGroupBy object,\n",
    "which will perform the appropriate apply/combine steps to produce the desired\n",
    "result:\n",
    "```python\n",
    "In[13]: df.groupby('key').sum()\n",
    "Out[13]: data\n",
    " key\n",
    " A 3\n",
    " B 5\n",
    " C 7\n",
    " ```\n",
    "The `sum()` method is just one possibility here; you can apply virtually any common\n",
    "Pandas or NumPy aggregation function, as well as virtually any valid DataFrame\n",
    "operation, as we will see in the following discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
